"""Issueè‡ªå‹•æ”¹å–„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - Phase 2å®Ÿè£…ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆï¼‰

PEP-723å¯¾å¿œ: uvx ã§å®Ÿè¡Œå¯èƒ½

å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰:
1. é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: GitHub Actionsã‹ã‚‰è‡ªå‹•å®Ÿè¡Œï¼ˆIssueä½œæˆæ™‚ï¼‰
2. --dry-run: ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€èª­ã¿å–ã‚Šæ“ä½œã¯å®Ÿè¡Œï¼‰
3. --index-issues: RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨Issueã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
4. --update-single-issue: å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰
"""

import argparse
import dataclasses
import json
import os
import re
import sys
import subprocess
import tempfile
import uuid
from pathlib import Path
from typing import Any

import yaml
from google import genai
from google.genai.types import HarmCategory, HarmBlockThreshold
import voyageai
from langchain_text_splitters import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    FieldCondition,
    Filter,
    MatchValue,
    PayloadSchemaType,
    PointIdsList,
    PointStruct,
    VectorParams,
)


# ==================== è¨­å®šç®¡ç† ====================


@dataclasses.dataclass
class Config:
    """ç’°å¢ƒå¤‰æ•°ã®ä¸€å…ƒç®¡ç†ã‚¯ãƒ©ã‚¹"""

    # GitHubé–¢é€£ï¼ˆGitHub Actionså®Ÿè¡Œæ™‚ã«è‡ªå‹•è¨­å®šï¼‰
    github_repository: str = dataclasses.field(
        default_factory=lambda: os.environ.get("GITHUB_REPOSITORY", "")
    )
    github_token: str = dataclasses.field(
        default_factory=lambda: os.environ.get("GITHUB_TOKEN", "")
    )

    # Issueæƒ…å ±ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã«å¿…è¦ï¼‰
    issue_body: str = dataclasses.field(
        default_factory=lambda: os.environ.get("ISSUE_BODY", "")
    )
    issue_title: str = dataclasses.field(
        default_factory=lambda: os.environ.get("ISSUE_TITLE", "")
    )
    issue_number: str = dataclasses.field(
        default_factory=lambda: os.environ.get("ISSUE_NUMBER", "")
    )

    # LLM APIï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã«å¿…é ˆï¼‰
    gemini_api_key: str = dataclasses.field(
        default_factory=lambda: os.environ.get("GEMINI_API_KEY", "")
    )

    # RAGæ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - å…¨ã¦è¨­å®šã•ã‚ŒãŸå ´åˆã®ã¿æœ‰åŠ¹åŒ–ï¼‰
    qdrant_url: str = dataclasses.field(
        default_factory=lambda: os.environ.get("QDRANT_URL", "")
    )
    qdrant_api_key: str = dataclasses.field(
        default_factory=lambda: os.environ.get("QDRANT_API_KEY", "")
    )
    voyage_api_key: str = dataclasses.field(
        default_factory=lambda: os.environ.get("VOYAGE_API_KEY", "")
    )
    qdrant_collection_name: str = dataclasses.field(
        default_factory=lambda: os.environ.get(
            "QDRANT_COLLECTION_NAME", "ai-improve-issues"
        )
    )

    @property
    def is_rag_enabled(self) -> bool:
        """RAGæ©Ÿèƒ½ãŒæœ‰åŠ¹ã‹ã©ã†ã‹"""
        return bool(self.qdrant_url and self.qdrant_api_key and self.voyage_api_key)

    def validate_for_normal_mode(self):
        """é€šå¸¸ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã®å¿…é ˆç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯"""
        if not self.issue_number:
            raise ValueError("Error: ISSUE_NUMBER not set")
        if not self.gemini_api_key:
            raise ValueError("Error: GEMINI_API_KEY not set")

    def validate_for_github_operations(self):
        """GitHubæ“ä½œãŒå¿…è¦ãªå ´åˆã®ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯"""
        if not self.github_token:
            raise ValueError("Error: GITHUB_TOKEN not set")
        if not self.github_repository:
            raise ValueError("Error: GITHUB_REPOSITORY not set")

    def validate_for_rag_operations(self):
        """RAGæ“ä½œãŒå¿…è¦ãªå ´åˆã®ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯"""
        if not self.voyage_api_key:
            raise ValueError("Error: VOYAGE_API_KEY not set")
        if not self.qdrant_url:
            raise ValueError("Error: QDRANT_URL not set")
        if not self.qdrant_api_key:
            raise ValueError("Error: QDRANT_API_KEY not set")


# è¨­å®šã‚’èª­ã¿è¾¼ã¿
config = Config()


# ==================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ====================


def find_repo_root() -> Path:
    """ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã‚’æ¢ç´¢

    Returns:
        Path: ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰.gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
    # (uvxå®Ÿè¡Œæ™‚ã¯__file__ãŒsite-packagesã‚’æŒ‡ã™ãŸã‚ã€cwdã‚’èµ·ç‚¹ã¨ã™ã‚‹)
    current = Path.cwd().resolve()
    for parent in [current] + list(current.parents):
        if (parent / ".git").exists():
            return parent

    # .git ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿”ã™
    return current


# ==================== ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®š ====================


@dataclasses.dataclass
class TemplateConfig:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®š"""

    name: str
    issue_template_file: str
    system_prompt: str
    keywords: list[str]


@dataclasses.dataclass
class ImproveIssueSettings:
    """Issueæ”¹å–„è¨­å®š"""

    templates: dict[str, TemplateConfig]
    default_template: str

    def validate(self):
        """è¨­å®šã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not self.templates:
            raise ValueError("Error: templates is empty")
        if self.default_template not in self.templates:
            raise ValueError(
                f"Error: default_template '{self.default_template}' not found in templates"
            )


def load_settings() -> ImproveIssueSettings:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    Returns:
        ImproveIssueSettings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Raises:
        FileNotFoundError: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        ValueError: è¨­å®šå†…å®¹ãŒä¸æ­£ãªå ´åˆ
    """
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    config_path = os.environ.get("AI_IMPROVE_ISSUE_CONFIG")
    if config_path:
        config_file = Path(config_path)
    else:
        repo_root = find_repo_root()
        config_file = repo_root / ".ai_improve_issue.yml"

    if not config_file.exists():
        raise FileNotFoundError(
            f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_file}\n"
            f"ç’°å¢ƒå¤‰æ•° AI_IMPROVE_ISSUE_CONFIG ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã™ã‚‹ã‹ã€\n"
            f"ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã« .ai_improve_issue.yml ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚"
        )

    # YAMLèª­ã¿è¾¼ã¿
    with open(config_file, encoding="utf-8") as f:
        data = yaml.safe_load(f)

    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not data:
        raise ValueError("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")

    if "templates" not in data:
        raise ValueError("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã« 'templates' ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    if "default_template" not in data:
        raise ValueError("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã« 'default_template' ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨­å®šã®æ§‹ç¯‰
    templates = {}
    for name, tmpl_data in data["templates"].items():
        if not isinstance(tmpl_data, dict):
            raise ValueError(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{name}' ã®å®šç¾©ãŒä¸æ­£ã§ã™")

        required_fields = ["issue_template_file", "system_prompt", "keywords"]
        for field in required_fields:
            if field not in tmpl_data:
                raise ValueError(
                    f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{name}' ã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒã‚ã‚Šã¾ã›ã‚“"
                )

        templates[name] = TemplateConfig(
            name=name,
            issue_template_file=tmpl_data["issue_template_file"],
            system_prompt=tmpl_data["system_prompt"],
            keywords=tmpl_data["keywords"],
        )

    settings = ImproveIssueSettings(
        templates=templates,
        default_template=data["default_template"],
    )

    settings.validate()

    return settings


# ==================== ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ ====================


def load_template_content(template: TemplateConfig) -> str:
    """ISSUE_TEMPLATEãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    repo_root = find_repo_root()
    template_file = (
        repo_root / ".github" / "ISSUE_TEMPLATE" / f"{template.issue_template_file}.md"
    )

    if not template_file.exists():
        raise FileNotFoundError(
            f"Issueãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {template_file}"
        )

    with open(template_file, encoding="utf-8") as f:
        content = f.read()

    # frontmatter (---ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†) ã‚’é™¤å»
    lines = content.split("\n")
    if lines and lines[0] == "---":
        # 2ã¤ç›®ã®---ã‚’æ¢ã™
        end_idx = None
        for i in range(1, len(lines)):
            if lines[i] == "---":
                end_idx = i
                break
        if end_idx is not None:
            content = "\n".join(lines[end_idx + 1 :])

    return content.strip()


# ==================== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ====================


def get_improve_prompt(
    template_name: str,
    issue_body: str,
    issue_title: str = "",
    similar_issues: list[dict[str, Any]] | None = None,
    settings: ImproveIssueSettings | None = None,
) -> tuple[str, str]:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        system_instruction, prompt:
    """
    if settings is None:
        raise ValueError("settings is required")

    tmpl = settings.templates[template_name]
    template_content = load_template_content(tmpl)
    system_instruction = f"""
{tmpl.system_prompt}

ã€Issueè¨˜è¿°ã€‘ã«ã¤ã„ã¦ã€ã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘ã®å†…å®¹ã‚’å‚è€ƒã«ã—ã¦ã€æ¦‚è¦ã‚’æ•¬ä½“ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘ã«é¡ä¼¼ã™ã‚‹å†…å®¹ãŒã‚ã‚‹ã‹åˆ¤å®šã—ã€ã€## é¡ä¼¼Issueã€‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãã®idã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—å­˜åœ¨ã—ãªã„å ´åˆã¯ã€Œãªã—ã€ã¨å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›å½¢å¼ä»¥å¤–ã®æ–‡ç« ã¯ä¸è¦ã§ã™ã€‚
"""

    prompt = f"""
ã€Issueè¨˜è¿°ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {issue_title}
æœ¬æ–‡: {issue_body}

ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘
{template_content}
"""

    # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
    if similar_issues and len(similar_issues) > 0:
        similar_info = (
            "\n\nã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘\nä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n"
        )
        for i, issue in enumerate(similar_issues, 1):
            similar_info += f"""
ã€å‚è€ƒIssue {i}ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: {issue["issue_title"]}
- æœ¬æ–‡æŠœç²‹: {issue["issue_body"][:200]}...
- é¡ä¼¼åº¦: {issue["similarity"]:.1%}
"""
        similar_info += "\nä¸Šè¨˜ã®å‚è€ƒIssueã‹ã‚‰ã€è¨˜è¿°ã‚¹ã‚¿ã‚¤ãƒ«ã‚„å¿…è¦ãªæƒ…å ±é …ç›®ã‚’å­¦ã³ã€ã‚ˆã‚Šå…·ä½“çš„ã§å®Ÿç”¨çš„ãªä¾‹æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        prompt += similar_info

    return system_instruction, prompt


# ==================== LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ====================


class TextProcessAgent:
    """ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šã¨æ–‡ç« ç”Ÿæˆï¼‰"""

    # å®‰å…¨æ€§è¨­å®šã‚’ç·©å’Œï¼ˆæŠ€è¡“çš„ãªå†…å®¹ã«å¯¾å¿œï¼‰
    _SAFETY_SETTINGS = [
        genai.types.SafetySetting(
            category=HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
        genai.types.SafetySetting(
            category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold=HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
        genai.types.SafetySetting(
            category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold=HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
        genai.types.SafetySetting(
            category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
    ]

    def __init__(self, llm_api_key: str, model: str = "gemini-2.5-flash"):
        """ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šã¨æ–‡ç« ç”Ÿæˆã‚’æ‹…å½“ã™ã‚‹LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼‰

        Args:
            llm_api_key: APIã‚­ãƒ¼
            model: ãƒ¢ãƒ‡ãƒ«åï¼ˆ2025å¹´11æœˆæ™‚ç‚¹ã®æ¨å¥¨ï¼‰
                - Phase 0: 'gemini-2.0-flash-lite' (æ¤œè¨¼ç”¨ã€æ¥µä½ã‚³ã‚¹ãƒˆ)
                - Phase 1-2: 'gemini-2.5-flash' (ã‚³ã‚¹ãƒ‘è‰¯å¥½)
                - Phase 2: 'claude-3.7-sonnet' (å“è³ªé‡è¦–)
        """
        self.client = genai.Client(api_key=llm_api_key)
        self.model_name = model

    def detect_template(
        self, issue_body: str, issue_title: str, settings: ImproveIssueSettings
    ) -> str:
        """Issueæœ¬æ–‡ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆ¤å®šï¼ˆLLMãƒ™ãƒ¼ã‚¹å˜ä¸€é¸æŠï¼‰

        Args:
            issue_body: Issueæœ¬æ–‡
            issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
            settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        Returns:
            ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåï¼ˆå¤±æ•—æ™‚ã‚„æ›–æ˜§æ™‚ã¯ `default_template`ï¼‰
        """
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæƒ…å ±ã‚’è¦ç´„ã—ã¦LLMã«æ¸¡ã™
        tmpl_summaries: list[dict[str, Any]] = []
        for name, tmpl in settings.templates.items():
            sp = (tmpl.system_prompt or "").strip()
            if len(sp) > 300:
                sp = sp[:300]
            kws = (tmpl.keywords or [])[:10]
            tmpl_summaries.append(
                {
                    "name": name,
                    "keywords": kws,
                    "system_prompt": sp,
                }
            )

        system_instruction = (
            "ã‚ãªãŸã¯Issueã®å†…å®¹ã‹ã‚‰æœ€é©ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’1ã¤ã ã‘é¸ã¶åˆ†é¡å™¨ã§ã™ã€‚\n"
            "æä¾›ã•ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå€™è£œã®ä¸­ã‹ã‚‰ã€è¨˜è¿°ã®ç›®çš„ãƒ»æ§‹é€ ã«æœ€ã‚‚é©åˆã™ã‚‹ã‚‚ã®ã‚’å³å¯†ã«1ä»¶é¸ã‚“ã§ãã ã•ã„ã€‚\n"
            "å‡ºåŠ›ã¯JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã€è¿½åŠ èª¬æ˜ã¯ç¦æ­¢ã§ã™ã€‚"
        )

        prompt = (
            "ã€Issueã€‘\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {issue_title}\n"
            f"æœ¬æ–‡: {issue_body}\n\n"
            "ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå€™è£œä¸€è¦§(JSON)ã€‘\n"
            f"{json.dumps(tmpl_summaries, ensure_ascii=False)}\n\n"
            "ä»¥ä¸‹ã®å½¢å¼ã§å³å¯†ã«1ä»¶ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
            '{"template": "<name>"}'
        )

        # ä½ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»ä½æ¸©åº¦ã§åˆ†é¡å®Ÿè¡Œï¼ˆAPIå‘¼ã³å‡ºã—ã¨textå–å¾—ã®ã¿tryï¼‰
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                system_instruction=[system_instruction],
                max_output_tokens=256,
                temperature=0.1,
                safety_settings=self._SAFETY_SETTINGS,
            ),
        )

        try:
            text = response.text or ""
        except ValueError as e:
            print(
                f"response.text å–å¾—ã§ã‚¨ãƒ©ãƒ¼ ({e})ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            )
            return settings.default_template

        print(f"é¸æŠã•ã‚ŒãŸå†…å®¹: {text=}")
        # {.*} éƒ¨åˆ†ã®ã¿æŠ½å‡º
        text = re.sub(r"(?s).*?(\{.*?\}).*", r"\1", text)

        try:
            selected: dict[str, str] = json.loads(text)
        except json.JSONDecodeError as e:
            print(
                f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ†ã‚­ã‚¹ãƒˆ: {text}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            )
            return settings.default_template

        name = selected.get("template", "")
        if name not in settings.templates:
            print(
                f"ä¸æ˜ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå '{name}'ã€‚æœ‰åŠ¹ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {list(settings.templates.keys())}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            )
            return settings.default_template

        return name

    def generate(
        self, system_instruction: str, prompt: str, max_tokens: int = 5000
    ) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æ–‡ç« ã‚’ç”Ÿæˆ

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                system_instruction=[system_instruction],
                max_output_tokens=max_tokens,
                temperature=0.7,
                safety_settings=self._SAFETY_SETTINGS,
            ),
        )

        try:
            return response.text
        except ValueError:
            pass

        # finish_reasonã‚’ç¢ºèªã—ã¦ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        finish_reason = None
        if response.candidates:
            finish_reason = response.candidates[0].finish_reason

        if finish_reason == 2:  # SAFETY
            return "âš ï¸ AIã«ã‚ˆã‚‹ç”ŸæˆãŒå®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Šãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚Issueå†…å®¹ã‚’ç¢ºèªã—ã€æ‰‹å‹•ã§è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚"
        elif finish_reason == 3:  # RECITATION
            return "âš ï¸ AIã«ã‚ˆã‚‹ç”ŸæˆãŒè‘—ä½œæ¨©ä¿è­·ã«ã‚ˆã‚Šãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚åˆ¥ã®è¡¨ç¾ã§è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚"
        elif finish_reason == 4:  # OTHER
            return "âš ï¸ AIã«ã‚ˆã‚‹ç”ŸæˆãŒåˆ¶é™ã•ã‚Œã¾ã—ãŸã€‚æ‰‹å‹•ã§è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚"

        return "âš ï¸ AIã«ã‚ˆã‚‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚"


# ==================== RAGã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (Phase 2) ====================


class VoyageEmbeddingClient:
    """Voyage AI Embeddingã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, api_key: str, model: str = "voyage-3.5-lite"):
        """
        Args:
            api_key: Voyage AI APIã‚­ãƒ¼
            model: ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: voyage-3.5-liteï¼‰
        """
        self.client = voyageai.Client(api_key=api_key)
        self.model = model

    def generate_embedding(self, text: str, dimensions: int = 256) -> list[float]:
        """ãƒ†ã‚­ã‚¹ãƒˆã®Embeddingã‚’ç”Ÿæˆ

        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            dimensions: å‡ºåŠ›æ¬¡å…ƒæ•°ï¼ˆ256, 512, 1024ï¼‰

        Returns:
            Embeddingãƒ™ã‚¯ãƒˆãƒ«
        """
        result = self.client.embed(
            texts=[text], model=self.model, output_dimension=dimensions
        )
        return result.embeddings[0]


class QdrantSearchClient:
    """Qdrantæ¤œç´¢ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(
        self, url: str, api_key: str, collection_name: str = "ai-improve-issues"
    ):
        """Qdrantã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–

        Args:
            url: Qdrant Cloudã®URL
            api_key: Qdrant APIã‚­ãƒ¼
            collection_name: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
        """
        self.client = QdrantClient(url=url, api_key=api_key)
        self.collection_name = collection_name

    def ensure_collection(self, vector_size: int = 256):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€ãªã‘ã‚Œã°ä½œæˆ"""
        collections = self.client.get_collections().collections
        collection_names = [col.name for col in collections]
        if self.collection_name not in collection_names:
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),
            )
            print(f"Collection '{self.collection_name}' created")
            self.client.create_payload_index(
                collection_name=self.collection_name,
                field_name="issue_number",
                field_schema=PayloadSchemaType.INTEGER,
            )

    def search_similar_issues(
        self,
        query_vector: list[float],
        limit: int = 3,
        exclude_issue_number: int | None = None,
    ) -> list[dict[str, Any]]:
        """é¡ä¼¼Issueæ¤œç´¢ï¼ˆãƒãƒ£ãƒ³ã‚¯å¯¾å¿œï¼‰

        Args:
            query_vector: ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«
            limit: å–å¾—ä»¶æ•°ï¼ˆTop-Kï¼‰- Issueæ•°ï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ã§ã¯ãªã„ï¼‰

        Returns:
            é¡ä¼¼Issueæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        # ã‚ˆã‚Šå¤šãã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã—ã¦Issueã”ã¨ã«é›†ç´„
        response = self.client.query_points(
            collection_name=self.collection_name,
            query=query_vector,
            limit=limit * 5,  # ä½™è£•ã‚’æŒã£ã¦å–å¾—
        )

        points = getattr(response, "points", [])
        if not points:
            return []

        # Issueã”ã¨ã«æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é›†ç´„
        issue_map = {}
        for result in points:
            issue_num = result.payload.get("issue_number")
            # é™¤å¤–å¯¾è±¡ã®Issueç•ªå·ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if exclude_issue_number is not None and issue_num == exclude_issue_number:
                continue
            if (
                issue_num not in issue_map
                or result.score > issue_map[issue_num]["similarity"]
            ):
                # ãƒãƒ£ãƒ³ã‚¯ã¾ãŸã¯å…¨æ–‡ã‚’å–å¾—
                issue_body = result.payload.get(
                    "issue_body_chunk"
                ) or result.payload.get("issue_body", "")

                issue_map[issue_num] = {
                    "issue_number": issue_num,
                    "issue_title": result.payload.get("issue_title", ""),
                    "issue_body": issue_body[:500],
                    "state": result.payload.get("state", ""),
                    "url": result.payload.get("url", ""),
                    "similarity": result.score,
                }

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½limitä»¶ã‚’è¿”ã™
        similar_issues = sorted(
            issue_map.values(), key=lambda x: x["similarity"], reverse=True
        )[:limit]

        return similar_issues

    def upsert_issue_chunks(
        self,
        issue_number: int,
        chunks: list[str],
        vectors: list[list[float]],
        title: str,
        state: str,
        url: str,
        labels: list[str],
    ):
        """Issueã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²ã¾ãŸã¯æ›´æ–°

        Args:
            issue_number: Issueç•ªå·
            chunks: Issueæœ¬æ–‡ã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
            vectors: å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ãƒªã‚¹ãƒˆ
            title: Issueã‚¿ã‚¤ãƒˆãƒ«
            state: Issueã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆopen/closedï¼‰
            url: Issueã®URL
            labels: ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆ
        """
        # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤ï¼ˆissue_numberã§å§‹ã¾ã‚‹IDã‚’æ¤œç´¢ã—ã¦å‰Šé™¤ï¼‰
        ids_to_delete: list[str] = []
        offset: dict | None = None
        while True:
            existing_points, next_offset = self.client.scroll(
                collection_name=self.collection_name,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(
                            key="issue_number",
                            match=MatchValue(value=issue_number),
                        )
                    ]
                ),
                limit=256,
                offset=offset,
                with_payload=False,
                with_vectors=False,
            )

            if not existing_points:
                break

            ids_to_delete.extend(str(point.id) for point in existing_points)

            if next_offset is None:
                break

            offset = next_offset

        if ids_to_delete:
            self.client.delete(
                collection_name=self.collection_name,
                points_selector=PointIdsList(points=ids_to_delete),
            )

        # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ç™»éŒ²
        points = []
        for i, (chunk, vector) in enumerate(zip(chunks, vectors)):
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload={
                    "issue_number": issue_number,
                    "chunk_index": i,
                    "issue_title": title,
                    "issue_body_chunk": chunk,
                    "state": state,
                    "url": url,
                    "labels": labels,
                },
            )
            points.append(point)

        self.client.upsert(collection_name=self.collection_name, points=points)
        print(f"Issue #{issue_number} indexed with {len(chunks)} chunks")


# ==================== GitHub API ====================


def fetch_issue_from_github(issue_number: int) -> dict | None:
    """GitHub APIã‹ã‚‰Issueæƒ…å ±ã‚’å–å¾—

    Args:
        issue_number: Issueç•ªå·

    Returns:
        Issueæƒ…å ±ã®è¾æ›¸ã€å–å¾—å¤±æ•—æ™‚ã¯None
    """
    if not config.github_repository:
        print("Error: GITHUB_REPOSITORY not set")
        return None

    cmd = ["gh", "api", f"/repos/{config.github_repository}/issues/{issue_number}"]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        check=True,
        env={
            "GH_TOKEN": config.github_token,
            "GH_REPO": config.github_repository,
        },
    )
    issue_data = json.loads(result.stdout)
    labels = [label["name"] for label in issue_data["labels"]]
    return {
        "number": int(issue_data["number"]),
        "title": issue_data["title"],
        "body": issue_data["body"],
        "state": issue_data["state"],
        "url": issue_data["html_url"],
        "labels": labels,
    }


def fetch_all_issues(start: int = 1, end: int | None = None) -> list[dict]:
    """å…¨Issueæƒ…å ±ã‚’å–å¾—

    Args:
        start: é–‹å§‹Issueç•ªå·
        end: çµ‚äº†Issueç•ªå·ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰

    Returns:
        Issueæƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    if not config.github_repository:
        print("Error: GITHUB_REPOSITORY not set")
        return []

    # gh issue list ã§Issueç•ªå·ä¸€è¦§ã‚’å–å¾—
    cmd = [
        "gh",
        "issue",
        "list",
        "--state",
        "all",
        "--limit",
        "1000",
        "--json",
        "number",
    ]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        check=True,
        cwd=os.getcwd(),
        env={
            "GH_TOKEN": config.github_token,
            "GH_REPO": config.github_repository,
        },
    )
    issues_data = json.loads(result.stdout)
    issue_numbers = [issue["number"] for issue in issues_data]

    # ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if end is not None:
        issue_numbers = [n for n in issue_numbers if start <= n <= end]
    else:
        issue_numbers = [n for n in issue_numbers if n >= start]

    # å„Issueã®è©³ç´°ã‚’å–å¾—
    issues = []
    for num in issue_numbers:
        issue = fetch_issue_from_github(num)
        if issue:
            issues.append(issue)

    return issues


# ==================== ãƒãƒ£ãƒ³ã‚¯å‡¦ç† ====================


def create_issue_chunks(issue_title: str, issue_body: str) -> list[str]:
    """Issueæœ¬æ–‡ã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²

    Args:
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        issue_body: Issueæœ¬æ–‡

    Returns:
        ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’çµåˆ
    full_text = f"{issue_title}\n\n{issue_body}"

    # çŸ­ã„å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ä¸è¦
    if len(full_text) <= 400:
        return [full_text]

    # LangChainã®RecursiveCharacterTextSplitterã‚’ä½¿ç”¨
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=400,
        chunk_overlap=50,
        separators=["ã€‚", "\n\n", "\n", " ", ""],  # æ—¥æœ¬èªå„ªå…ˆã®åŒºåˆ‡ã‚Šæ–‡å­—
    )

    chunks = splitter.split_text(full_text)
    return chunks


def create_embeddings_for_chunks(
    chunks: list[str], embedding_client: "VoyageEmbeddingClient", dimensions: int = 256
) -> list[list[float]]:
    """ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã®Embeddingã‚’ç”Ÿæˆ

    Args:
        chunks: ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
        embedding_client: Embeddingã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        dimensions: Embeddingæ¬¡å…ƒæ•°

    Returns:
        Embeddingãƒ™ã‚¯ãƒˆãƒ«ãƒªã‚¹ãƒˆ
    """
    # Batch embed all chunks at once
    result = embedding_client.client.embed(
        texts=chunks, model=embedding_client.model, output_dimension=dimensions
    )
    return result.embeddings


# ==================== ãƒ¡ã‚¤ãƒ³å‡¦ç† ====================


def check_needs_improvement(issue_body: str, issue_title: str) -> bool:
    """Issueæ”¹å–„ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯

    Args:
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«

    Returns:
        True: æ”¹å–„ãŒå¿…è¦, False: æ”¹å–„ä¸è¦
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’çµåˆã—ã€ç©ºç™½ã‚’é™¤å»ã—ã¦æ–‡å­—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    combined = (issue_title or "") + (issue_body or "")
    text_without_spaces = combined.replace(" ", "").replace("\n", "").replace("\t", "")

    # 10æ–‡å­—æœªæº€ã®å ´åˆã¯æ”¹å–„ä¸è¦
    if len(text_without_spaces) < 10:
        return False

    return True


def post_comment_via_gh(issue_number: str, content: str) -> None:
    """GitHub CLIçµŒç”±ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ•ç¨¿

    Args:
        issue_number: Issueç•ªå·
        content: ã‚³ãƒ¡ãƒ³ãƒˆå†…å®¹
    """
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ¬æ–‡ã‚’æ›¸ãå‡ºã—
    with tempfile.NamedTemporaryFile(mode="w", encoding="utf-8", suffix=".md") as f:
        f.write(content)
        f.flush()
        # GitHub CLIã§ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
        subprocess.run(
            ["gh", "issue", "comment", issue_number, "--body-file", f.name],
            check=True,
        )
    print(f"Comment posted successfully to issue #{issue_number}")


def generate_improved_content(
    issue_body: str,
    issue_title: str,
    llm_api_key: str,
    similar_issues: list[dict[str, Any]] | None = None,
    settings: ImproveIssueSettings | None = None,
) -> tuple[str, str]:
    """Issueå†…å®¹ã‚’æ”¹å–„ã—ãŸä¾‹æ–‡ã‚’ç”Ÿæˆï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        llm_api_key: LLM APIã‚­ãƒ¼
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        (improved_content, template_name): æ”¹å–„ã•ã‚ŒãŸå†…å®¹ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
    """
    if settings is None:
        raise ValueError("settings is required")

    # LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = TextProcessAgent(llm_api_key=llm_api_key)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®š
    template_name = client.detect_template(issue_body, issue_title, settings)
    print(f"Detected template: {template_name}")

    # æ–‡ç« ç”Ÿæˆ
    system_instruction, prompt = get_improve_prompt(
        template_name, issue_body, issue_title, similar_issues, settings
    )
    improved_content = client.generate(system_instruction, prompt)
    print("Content generated successfully")

    return improved_content, template_name


def format_comment(
    improved_content: str,
    template_name: str,
    similar_issues: list[dict[str, Any]] | None = None,
) -> str:
    """ã‚³ãƒ¡ãƒ³ãƒˆç”¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ–‡å­—åˆ—ã‚’ç”Ÿæˆï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        improved_content: æ”¹å–„ã•ã‚ŒãŸå†…å®¹
        template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰

    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ã‚³ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—
    """
    template_display_names = {
        "feature_request": "æ©Ÿèƒ½è¦ä»¶",
        "bug_report": "ãƒã‚°å ±å‘Š",
    }
    template_display = template_display_names.get(template_name, template_name)

    comment = f"""## ğŸ¤– AIã«ã‚ˆã‚‹Issueè¨˜å…¥ä¾‹

**é¸å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: {template_display}

---

{improved_content}

---
"""

    # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
    if similar_issues and len(similar_issues) > 0:
        comment += "\n### ğŸ“š å‚è€ƒã«ã—ãŸé¡ä¼¼Issue\n\nã“ã®ä¾‹æ–‡ã¯ä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼š\n\n"
        for i, issue in enumerate(similar_issues, 1):
            comment += f"""{i}. **#{issue["issue_number"]}: {issue["issue_title"]}** ({issue["state"]})
   - é¡ä¼¼åº¦: {issue["similarity"]:.0%}
   - {issue["url"]}

"""
        comment += "---\n\n"

    comment += """ğŸ’¡ **ä½¿ã„æ–¹**: ä¸Šè¨˜ã®ä¾‹æ–‡ã‚’å‚è€ƒã«ã€Issueæœ¬æ–‡ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚"""
    if similar_issues and len(similar_issues) > 0:
        comment += "é¡ä¼¼Issueã‚‚ç¢ºèªã™ã‚‹ã¨ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
    else:
        comment += "å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åˆã‚ã›ã¦å†…å®¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"

    comment += "\n\n<!-- AI-generated comment -->\n"

    return comment


def index_all_issues(
    start: int = 1, end: int | None = None, settings: ImproveIssueSettings | None = None
):
    """å…¨Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²ï¼ˆ--index-issues ãƒ¢ãƒ¼ãƒ‰ï¼‰

    Args:
        start: é–‹å§‹Issueç•ªå·
        end: çµ‚äº†Issueç•ªå·ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    if settings is None:
        raise ValueError("settings is required")

    config.validate_for_github_operations()
    config.validate_for_rag_operations()

    print("=== RAG Indexing Mode ===")
    print("Fetching issues from GitHub...")

    # Issueä¸€è¦§å–å¾—
    issues = fetch_all_issues(start, end)
    if not issues:
        print("No issues found")
        sys.exit(0)

    print(f"Found {len(issues)} issues to index")

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    voyage_client = VoyageEmbeddingClient(api_key=config.voyage_api_key)
    qdrant_client = QdrantSearchClient(
        url=config.qdrant_url,
        api_key=config.qdrant_api_key,
        collection_name=config.qdrant_collection_name,
    )
    qdrant_client.ensure_collection(vector_size=256)

    # å„Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²
    success_count = 0
    for i, issue in enumerate(issues, 1):
        print(f"[{i}/{len(issues)}] Indexing issue #{issue['number']}...")

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = create_issue_chunks(issue["title"], issue["body"])

        # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

        # Qdrantã«ç™»éŒ²
        qdrant_client.upsert_issue_chunks(
            issue_number=issue["number"],
            chunks=chunks,
            vectors=vectors,
            title=issue["title"],
            state=issue["state"],
            url=issue["url"],
            labels=issue.get("labels", []),
        )
        success_count += 1

    print("\n=== Indexing Complete ===")
    print(f"Success: {success_count}/{len(issues)} issues")


def update_single_issue(
    issue_number: int, settings: ImproveIssueSettings | None = None
):
    """å˜ä¸€Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ï¼ˆ--update-single-issue ãƒ¢ãƒ¼ãƒ‰ï¼‰

    Args:
        issue_number: Issueç•ªå·
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    if settings is None:
        raise ValueError("settings is required")

    config.validate_for_github_operations()
    config.validate_for_rag_operations()

    print(f"=== Update Single Issue #{issue_number} ===")

    # Issueæƒ…å ±å–å¾—
    issue = fetch_issue_from_github(issue_number)
    if not issue:
        print(f"Error: Failed to fetch issue #{issue_number}")
        sys.exit(1)

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    voyage_client = VoyageEmbeddingClient(api_key=config.voyage_api_key)
    qdrant_client = QdrantSearchClient(
        url=config.qdrant_url,
        api_key=config.qdrant_api_key,
        collection_name=config.qdrant_collection_name,
    )
    qdrant_client.ensure_collection(vector_size=256)

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = create_issue_chunks(issue["title"], issue["body"])

    # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
    vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

    # Qdrantã«ç™»éŒ²
    qdrant_client.upsert_issue_chunks(
        issue_number=issue["number"],
        chunks=chunks,
        vectors=vectors,
        title=issue["title"],
        state=issue["state"],
        url=issue["url"],
        labels=issue.get("labels", []),
    )

    print(f"Issue #{issue_number} updated successfully")


def main():
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
        settings = load_settings()
        print("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except (FileNotFoundError, ValueError) as e:
        print(str(e))
        sys.exit(1)

    # å¼•æ•°è§£æ
    parser = argparse.ArgumentParser(description="Issueè‡ªå‹•æ”¹å–„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (Phase 2)")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰",
    )
    parser.add_argument(
        "--index-issues",
        action="store_true",
        help="RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨Issueã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰",
    )
    parser.add_argument(
        "--update-single-issue",
        type=int,
        help="å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰ï¼ˆæŒ‡å®šã—ãŸIssueç•ªå·ã‚’æ›´æ–°ï¼‰",
    )
    parser.add_argument(
        "--start", type=int, default=1, help="RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é–‹å§‹Issueç•ªå·"
    )
    parser.add_argument("--end", type=int, help="RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ‚äº†Issueç•ªå·")
    args = parser.parse_args()

    # RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
    if args.index_issues:
        index_all_issues(start=args.start, end=args.end, settings=settings)
        sys.exit(0)

    # å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰
    if args.update_single_issue:
        update_single_issue(args.update_single_issue, settings=settings)
        sys.exit(0)

    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: Issueæ”¹å–„
    # å¿…é ˆç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    try:
        config.validate_for_normal_mode()
    except ValueError as e:
        print(str(e))
        sys.exit(1)

    # æ”¹å–„ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
    if not check_needs_improvement(config.issue_body, config.issue_title):
        print(f"Issue #{config.issue_number} does not need improvement (too short)")
        sys.exit(0)

    print(f"Processing issue #{config.issue_number}")
    print(f"Title: {config.issue_title}")
    print(f"Body length: {len(config.issue_body)} characters")

    # RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
    similar_issues = None

    if config.is_rag_enabled:
        print("RAG mode: Enabled")
        # RAGæ¤œç´¢
        voyage_client = VoyageEmbeddingClient(api_key=config.voyage_api_key)
        qdrant_client = QdrantSearchClient(
            url=config.qdrant_url,
            api_key=config.qdrant_api_key,
            collection_name=config.qdrant_collection_name,
        )
        qdrant_client.ensure_collection(vector_size=256)

        # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        query_text = f"{config.issue_title}\n{config.issue_body}"
        query_vector = voyage_client.generate_embedding(query_text, dimensions=256)

        # é¡ä¼¼Issueæ¤œç´¢ï¼ˆè‡ªåˆ†è‡ªèº«ã‚’é™¤å¤–ï¼‰
        similar_issues = qdrant_client.search_similar_issues(
            query_vector, limit=3, exclude_issue_number=int(config.issue_number)
        )

        if similar_issues:
            print(f"Found {len(similar_issues)} similar issues")
            for i, sim in enumerate(similar_issues, 1):
                print(
                    f"  {i}. #{sim['issue_number']}: {sim['issue_title'][:50]}... "
                    f"(similarity: {sim['similarity']:.1%})"
                )
        else:
            print("No similar issues found")
    else:
        print("RAG mode: Disabled")

    # æ”¹å–„å†…å®¹ã‚’ç”Ÿæˆ
    improved_content, template_name = generate_improved_content(
        config.issue_body,
        config.issue_title,
        config.gemini_api_key,
        similar_issues,
        settings,
    )

    # ã‚³ãƒ¡ãƒ³ãƒˆç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    output = format_comment(improved_content, template_name, similar_issues)

    # --dry-run ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã®ã¿
    if args.dry_run:
        print("\n" + "=" * 60)
        print("[DRY RUN] ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        print("=" * 60)
        print(output)
        print("=" * 60)
        sys.exit(0)

    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: GitHub CLIã§ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
    if not config.github_token:
        print("Error: GITHUB_TOKEN not found")
        sys.exit(1)

    post_comment_via_gh(config.issue_number, output)

    # RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²ï¼ˆä¾‹æ–‡ç”Ÿæˆå¾Œï¼‰
    if not config.is_rag_enabled:
        print("QDRANT_* and VOYAGE_* env values are required to enable RAG mode.")
        sys.exit(0)

    print("Indexing current issue to RAG...")
    voyage_client = VoyageEmbeddingClient(api_key=config.voyage_api_key)
    qdrant_client = QdrantSearchClient(
        url=config.qdrant_url,
        api_key=config.qdrant_api_key,
        collection_name=config.qdrant_collection_name,
    )
    qdrant_client.ensure_collection(vector_size=256)

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = create_issue_chunks(config.issue_title, config.issue_body)

    # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
    vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

    # Issueã®URLç”Ÿæˆ
    issue_url = (
        f"https://github.com/{config.github_repository}/issues/{config.issue_number}"
        if config.github_repository
        else ""
    )

    qdrant_client.upsert_issue_chunks(
        issue_number=int(config.issue_number),
        chunks=chunks,
        vectors=vectors,
        title=config.issue_title,
        state="open",
        url=issue_url,
        labels=[],
    )
    print("Issue indexed successfully")


if __name__ == "__main__":
    main()
