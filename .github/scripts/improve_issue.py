# /// script
# dependencies = [
#   "google-generativeai>=0.8.3",
#   "voyageai>=0.2.3",
#   "qdrant-client==1.16.*",
#   "langchain-text-splitters>=0.3.0",
# ]
# ///
"""Issueè‡ªå‹•æ”¹å–„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - Phase 2å®Ÿè£…

PEP-723å¯¾å¿œ: uvx ã§å®Ÿè¡Œå¯èƒ½

å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰:
1. é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: GitHub Actionsã‹ã‚‰è‡ªå‹•å®Ÿè¡Œï¼ˆIssueä½œæˆæ™‚ï¼‰
2. --dry-run: ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€èª­ã¿å–ã‚Šæ“ä½œã¯å®Ÿè¡Œï¼‰
3. --index-issues: RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨Issueã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
4. --update-single-issue: å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰
"""

import argparse
import json
import os
import sys
import subprocess
import tempfile
import uuid
from pathlib import Path
from typing import Literal, Any

import google.generativeai as genai
import voyageai
from langchain_text_splitters import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    FieldCondition,
    Filter,
    MatchValue,
    PayloadSchemaType,
    PointIdsList,
    PointStruct,
    VectorParams,
)


# å‹å®šç¾©
TemplateType = Literal["feature_request", "bug_report"]

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå½¹å‰²ã¨æŒ‡ç¤º
ROLE_AND_INSTRUCTIONS = {
    "feature_request": """ã‚ãªãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®Issueè¨˜è¿°ã‚’ã€æ©Ÿèƒ½è¦ä»¶ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ²¿ã£ãŸå…·ä½“çš„ã§è©³ç´°ãªå†…å®¹ã«æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
- æŠ½è±¡çš„ãªè¡¨ç¾ã‚’é¿ã‘ã€å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„
- Issueè¨˜è¿°ã‹ã‚‰æ¨æ¸¬ã§ãã‚‹ç¯„å›²ã§è©³ç´°åŒ–ã—ã¦ãã ã•ã„
- ä¸æ˜ãªç‚¹ã¯ã€Œè¦ç¢ºèªã€ã¨ã—ã¦æ˜ç¤ºã—ã¦ãã ã•ã„
- Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„
- å„é …ç›®ã¯ç®‡æ¡æ›¸ãã§ã€å°‘ãªãã¨ã‚‚2-3é …ç›®è¨˜è¿°ã—ã¦ãã ã•ã„""",
    "bug_report": """ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ†ã‚¹ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒã‚°å ±å‘Šã‚’ã€è©³ç´°ã§å†ç¾å¯èƒ½ãªå½¢å¼ã«æ‹¡å¼µã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
- å†ç¾æ‰‹é †ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å¿…è¦æ€§ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„
- Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„""",
}

# ==================== ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ ====================


def load_template_content(template_name: str) -> str:
    """ISSUE_TEMPLATEãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    script_dir = Path(__file__).parent
    repo_root = script_dir.parent.parent
    template_file = repo_root / ".github" / "ISSUE_TEMPLATE" / f"{template_name}.md"

    if not template_file.exists():
        return ""

    with open(template_file, encoding="utf-8") as f:
        content = f.read()

    # frontmatter (---ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†) ã‚’é™¤å»
    lines = content.split("\n")
    if lines and lines[0] == "---":
        # 2ã¤ç›®ã®---ã‚’æ¢ã™
        end_idx = None
        for i in range(1, len(lines)):
            if lines[i] == "---":
                end_idx = i
                break
        if end_idx is not None:
            content = "\n".join(lines[end_idx + 1 :])

    return content.strip()


# ==================== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ====================


def get_improve_prompt(
    template_name: str,
    issue_body: str,
    issue_title: str = "",
    similar_issues: list[dict[str, Any]] | None = None,
) -> str:
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰

    Returns:
        LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    template_content = load_template_content(template_name)

    role = ROLE_AND_INSTRUCTIONS.get(
        template_name, ROLE_AND_INSTRUCTIONS["feature_request"]
    )

    prompt = f"""{role}

ã€Issueè¨˜è¿°ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {issue_title}
æœ¬æ–‡: {issue_body}

ã€å‡ºåŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘
ä»¥ä¸‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ²¿ã£ã¦å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ï¼š

{template_content}
"""

    # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
    if similar_issues and len(similar_issues) > 0:
        similar_info = "\n\nã€å‚è€ƒæƒ…å ±ã€‘\nä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n"
        for i, issue in enumerate(similar_issues, 1):
            similar_info += f"""
ã€å‚è€ƒIssue {i}ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: {issue["issue_title"]}
- æœ¬æ–‡æŠœç²‹: {issue["issue_body"][:200]}...
- é¡ä¼¼åº¦: {issue["similarity"]:.1%}
"""
        similar_info += "\nä¸Šè¨˜ã®å‚è€ƒIssueã‹ã‚‰ã€è¨˜è¿°ã‚¹ã‚¿ã‚¤ãƒ«ã‚„å¿…è¦ãªæƒ…å ±é …ç›®ã‚’å­¦ã³ã€ã‚ˆã‚Šå…·ä½“çš„ã§å®Ÿç”¨çš„ãªä¾‹æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        prompt += similar_info

    return prompt


# ==================== ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®š ====================


class TemplateDetector:
    """Issueå†…å®¹ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆ¤å®š"""

    KEYWORDS: dict[TemplateType, list[str]] = {
        "feature_request": ["æ©Ÿèƒ½", "è¿½åŠ ", "å¤‰æ›´", "æ”¹å–„", "ã—ãŸã„", "æ¬²ã—ã„", "å¿…è¦"],
        "bug_report": ["ãƒã‚°", "ã‚¨ãƒ©ãƒ¼", "ä¸å…·åˆ", "å‹•ã‹ãªã„", "å¤±æ•—", "å•é¡Œ"],
    }

    def detect(self, issue_body: str, issue_title: str = "") -> TemplateType:
        """Issueæœ¬æ–‡ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’åˆ¤å®šï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰"""
        text = f"{issue_title} {issue_body}".lower()

        scores: dict[TemplateType, int] = {}
        for template, keywords in self.KEYWORDS.items():
            score = sum(1 for keyword in keywords if keyword in text)
            scores[template] = score

        if not scores:
            return "feature_request"

        selected_tmpl = max(scores, key=scores.get)

        # ã‚¹ã‚³ã‚¢ãŒ0ã®å ´åˆï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãªã—ï¼‰ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§feature_request
        if scores[selected_tmpl] == 0:
            return "feature_request"

        return selected_tmpl


# ==================== LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ====================


class LLMClient:
    def __init__(self, api_key: str, model: str = "gemini-2.5-flash"):
        """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

        Args:
            api_key: APIã‚­ãƒ¼
            model: ãƒ¢ãƒ‡ãƒ«åï¼ˆ2025å¹´11æœˆæ™‚ç‚¹ã®æ¨å¥¨ï¼‰
                - Phase 0: 'gemini-2.0-flash-lite' (æ¤œè¨¼ç”¨ã€æ¥µä½ã‚³ã‚¹ãƒˆ)
                - Phase 1-2: 'gemini-2.5-flash' (ã‚³ã‚¹ãƒ‘è‰¯å¥½)
                - Phase 2: 'claude-3.7-sonnet' (å“è³ªé‡è¦–)
        """
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model)

    def generate(self, prompt: str, max_tokens: int = 2000) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æ–‡ç« ã‚’ç”Ÿæˆ"""
        response = self.model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=max_tokens,
                temperature=0.7,
            ),
        )
        return response.text


# ==================== RAGã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (Phase 2) ====================


class VoyageEmbeddingClient:
    """Voyage AI Embeddingã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, api_key: str, model: str = "voyage-3.5-lite"):
        """
        Args:
            api_key: Voyage AI APIã‚­ãƒ¼
            model: ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: voyage-3.5-liteï¼‰
        """
        self.client = voyageai.Client(api_key=api_key)
        self.model = model

    def generate_embedding(self, text: str, dimensions: int = 256) -> list[float]:
        """ãƒ†ã‚­ã‚¹ãƒˆã®Embeddingã‚’ç”Ÿæˆ

        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            dimensions: å‡ºåŠ›æ¬¡å…ƒæ•°ï¼ˆ256, 512, 1024ï¼‰

        Returns:
            Embeddingãƒ™ã‚¯ãƒˆãƒ«
        """
        result = self.client.embed(
            texts=[text], model=self.model, output_dimension=dimensions
        )
        return result.embeddings[0]


class QdrantSearchClient:
    """Qdrantæ¤œç´¢ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    COLLECTION_NAME = "improve-issues"

    def __init__(self, url: str, api_key: str):
        """
        Args:
            url: Qdrant Cloudã®URL
            api_key: Qdrant APIã‚­ãƒ¼
        """
        self.client = QdrantClient(url=url, api_key=api_key)

    def ensure_collection(self, vector_size: int = 256):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€ãªã‘ã‚Œã°ä½œæˆ"""
        collections = self.client.get_collections().collections
        collection_names = [col.name for col in collections]

        if self.COLLECTION_NAME not in collection_names:
            self.client.create_collection(
                collection_name=self.COLLECTION_NAME,
                vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),
            )
            print(f"Collection '{self.COLLECTION_NAME}' created")
            self.client.create_payload_index(
                collection_name=self.COLLECTION_NAME,
                field_name="issue_number",
                field_schema=PayloadSchemaType.INTEGER,
            )

    def search_similar_issues(
        self, query_vector: list[float], limit: int = 3
    ) -> list[dict[str, Any]]:
        """é¡ä¼¼Issueæ¤œç´¢ï¼ˆãƒãƒ£ãƒ³ã‚¯å¯¾å¿œï¼‰

        Args:
            query_vector: ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«
            limit: å–å¾—ä»¶æ•°ï¼ˆTop-Kï¼‰- Issueæ•°ï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ã§ã¯ãªã„ï¼‰

        Returns:
            é¡ä¼¼Issueæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        # ã‚ˆã‚Šå¤šãã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã—ã¦Issueã”ã¨ã«é›†ç´„
        response = self.client.query_points(
            collection_name=self.COLLECTION_NAME,
            query=query_vector,
            limit=limit * 5,  # ä½™è£•ã‚’æŒã£ã¦å–å¾—
        )

        points = getattr(response, "points", [])
        if not points:
            return []

        # Issueã”ã¨ã«æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é›†ç´„
        issue_map = {}
        for result in points:
            issue_num = result.payload.get("issue_number")
            if (
                issue_num not in issue_map
                or result.score > issue_map[issue_num]["similarity"]
            ):
                # ãƒãƒ£ãƒ³ã‚¯ã¾ãŸã¯å…¨æ–‡ã‚’å–å¾—
                issue_body = result.payload.get(
                    "issue_body_chunk"
                ) or result.payload.get("issue_body", "")

                issue_map[issue_num] = {
                    "issue_number": issue_num,
                    "issue_title": result.payload.get("issue_title", ""),
                    "issue_body": issue_body[:500],
                    "template_type": result.payload.get("template_type", ""),
                    "state": result.payload.get("state", ""),
                    "url": result.payload.get("url", ""),
                    "similarity": result.score,
                }

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½limitä»¶ã‚’è¿”ã™
        similar_issues = sorted(
            issue_map.values(), key=lambda x: x["similarity"], reverse=True
        )[:limit]

        return similar_issues

    def upsert_issue_chunks(
        self,
        issue_number: int,
        chunks: list[str],
        vectors: list[list[float]],
        title: str,
        template_type: str,
        state: str,
        url: str,
        labels: list[str],
    ):
        """Issueã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²ã¾ãŸã¯æ›´æ–°

        Args:
            issue_number: Issueç•ªå·
            chunks: Issueæœ¬æ–‡ã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
            vectors: å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ãƒªã‚¹ãƒˆ
            title: Issueã‚¿ã‚¤ãƒˆãƒ«
            template_type: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—
            state: Issueã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆopen/closedï¼‰
            url: Issueã®URL
            labels: ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆ
        """
        # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤ï¼ˆissue_numberã§å§‹ã¾ã‚‹IDã‚’æ¤œç´¢ã—ã¦å‰Šé™¤ï¼‰
        ids_to_delete: list[str] = []
        offset: dict | None = None
        while True:
            existing_points, next_offset = self.client.scroll(
                collection_name=self.COLLECTION_NAME,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(
                            key="issue_number",
                            match=MatchValue(value=issue_number),
                        )
                    ]
                ),
                limit=256,
                offset=offset,
                with_payload=False,
                with_vectors=False,
            )

            if not existing_points:
                break

            ids_to_delete.extend(str(point.id) for point in existing_points)

            if next_offset is None:
                break

            offset = next_offset

        if ids_to_delete:
            self.client.delete(
                collection_name=self.COLLECTION_NAME,
                points_selector=PointIdsList(points=ids_to_delete),
            )

        # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ç™»éŒ²
        points = []
        for i, (chunk, vector) in enumerate(zip(chunks, vectors)):
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload={
                    "issue_number": issue_number,
                    "chunk_index": i,
                    "issue_title": title,
                    "issue_body_chunk": chunk,
                    "template_type": template_type,
                    "state": state,
                    "url": url,
                    "labels": labels,
                },
            )
            points.append(point)

        self.client.upsert(collection_name=self.COLLECTION_NAME, points=points)
        print(f"Issue #{issue_number} indexed with {len(chunks)} chunks")


# ==================== GitHub API ====================


def fetch_issue_from_github(issue_number: int, github_token: str) -> dict | None:
    """GitHub APIã‹ã‚‰Issueæƒ…å ±ã‚’å–å¾—

    Args:
        issue_number: Issueç•ªå·
        github_token: GitHub Token

    Returns:
        Issueæƒ…å ±ã®è¾æ›¸ã€å–å¾—å¤±æ•—æ™‚ã¯None
    """
    repo = os.environ.get("GITHUB_REPOSITORY", "")
    if not repo:
        print("Error: GITHUB_REPOSITORY not set")
        return None

    cmd = ["gh", "api", f"/repos/{repo}/issues/{issue_number}"]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        check=True,
        env={
            "GH_TOKEN": github_token,
            "GH_REPO": repo,
        },
    )
    issue_data = json.loads(result.stdout)
    labels = [label["name"] for label in issue_data["labels"]]
    return {
        "number": int(issue_data["number"]),
        "title": issue_data["title"],
        "body": issue_data["body"],
        "state": issue_data["state"],
        "url": issue_data["html_url"],
        "labels": labels,
    }


def fetch_all_issues(
    github_token: str, start: int = 1, end: int | None = None
) -> list[dict]:
    """å…¨Issueæƒ…å ±ã‚’å–å¾—

    Args:
        github_token: GitHub Token
        start: é–‹å§‹Issueç•ªå·
        end: çµ‚äº†Issueç•ªå·ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰

    Returns:
        Issueæƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    repo = os.environ.get("GITHUB_REPOSITORY", "")
    if not repo:
        print("Error: GITHUB_REPOSITORY not set")
        return []

    # gh issue list ã§Issueç•ªå·ä¸€è¦§ã‚’å–å¾—
    cmd = [
        "gh",
        "issue",
        "list",
        "--state",
        "all",
        "--limit",
        "1000",
        "--json",
        "number",
    ]

    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        check=True,
        cwd=os.getcwd(),
        env={
            "GH_TOKEN": github_token,
            "GH_REPO": repo,
        },
    )
    issues_data = json.loads(result.stdout)
    issue_numbers = [issue["number"] for issue in issues_data]

    # ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if end is not None:
        issue_numbers = [n for n in issue_numbers if start <= n <= end]
    else:
        issue_numbers = [n for n in issue_numbers if n >= start]

    # å„Issueã®è©³ç´°ã‚’å–å¾—
    issues = []
    for num in issue_numbers:
        issue = fetch_issue_from_github(num, github_token)
        if issue:
            issues.append(issue)

    return issues


# ==================== ãƒãƒ£ãƒ³ã‚¯å‡¦ç† ====================


def create_issue_chunks(issue_title: str, issue_body: str) -> list[str]:
    """Issueæœ¬æ–‡ã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²

    Args:
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        issue_body: Issueæœ¬æ–‡

    Returns:
        ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’çµåˆ
    full_text = f"{issue_title}\n\n{issue_body}"

    # çŸ­ã„å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ä¸è¦
    if len(full_text) <= 400:
        return [full_text]

    # LangChainã®RecursiveCharacterTextSplitterã‚’ä½¿ç”¨
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=400,
        chunk_overlap=50,
        separators=["ã€‚", "\n\n", "\n", " ", ""],  # æ—¥æœ¬èªå„ªå…ˆã®åŒºåˆ‡ã‚Šæ–‡å­—
    )

    chunks = splitter.split_text(full_text)
    return chunks


def create_embeddings_for_chunks(
    chunks: list[str], embedding_client: "VoyageEmbeddingClient", dimensions: int = 256
) -> list[list[float]]:
    """ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã®Embeddingã‚’ç”Ÿæˆ

    Args:
        chunks: ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
        embedding_client: Embeddingã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        dimensions: Embeddingæ¬¡å…ƒæ•°

    Returns:
        Embeddingãƒ™ã‚¯ãƒˆãƒ«ãƒªã‚¹ãƒˆ
    """
    # Batch embed all chunks at once
    result = embedding_client.client.embed(
        texts=chunks, model=embedding_client.model, output_dimension=dimensions
    )
    return result.embeddings


# ==================== ãƒ¡ã‚¤ãƒ³å‡¦ç† ====================


def check_needs_improvement(issue_body: str, issue_title: str) -> bool:
    """Issueæ”¹å–„ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯

    Args:
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«

    Returns:
        True: æ”¹å–„ãŒå¿…è¦, False: æ”¹å–„ä¸è¦
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’çµåˆã—ã€ç©ºç™½ã‚’é™¤å»ã—ã¦æ–‡å­—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    combined = (issue_title or "") + (issue_body or "")
    text_without_spaces = combined.replace(" ", "").replace("\n", "").replace("\t", "")

    # 10æ–‡å­—æœªæº€ã®å ´åˆã¯æ”¹å–„ä¸è¦
    if len(text_without_spaces) < 10:
        return False

    return True


def post_comment_via_gh(issue_number: str, content: str) -> None:
    """GitHub CLIçµŒç”±ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ•ç¨¿

    Args:
        issue_number: Issueç•ªå·
        content: ã‚³ãƒ¡ãƒ³ãƒˆå†…å®¹
    """
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ¬æ–‡ã‚’æ›¸ãå‡ºã—
    with tempfile.NamedTemporaryFile(mode="w", encoding="utf-8", suffix=".md") as f:
        f.write(content)
        f.flush()
        # GitHub CLIã§ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
        subprocess.run(
            ["gh", "issue", "comment", issue_number, "--body-file", f.name],
            check=True,
        )
    print(f"Comment posted successfully to issue #{issue_number}")


def generate_improved_content(
    issue_body: str,
    issue_title: str,
    api_key: str,
    similar_issues: list[dict[str, Any]] | None = None,
) -> tuple[str, str]:
    """Issueå†…å®¹ã‚’æ”¹å–„ã—ãŸä¾‹æ–‡ã‚’ç”Ÿæˆï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        issue_body: Issueæœ¬æ–‡
        issue_title: Issueã‚¿ã‚¤ãƒˆãƒ«
        api_key: LLM APIã‚­ãƒ¼
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰

    Returns:
        (improved_content, template_name): æ”¹å–„ã•ã‚ŒãŸå†…å®¹ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
    """
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®š
    detector = TemplateDetector()
    template_name = detector.detect(issue_body, issue_title)
    print(f"Detected template: {template_name}")

    # LLMå‘¼ã³å‡ºã—
    client = LLMClient(api_key=api_key)
    prompt = get_improve_prompt(template_name, issue_body, issue_title, similar_issues)
    improved_content = client.generate(prompt)
    print("Content generated successfully")

    return improved_content, template_name


def format_comment(
    improved_content: str,
    template_name: str,
    similar_issues: list[dict[str, Any]] | None = None,
) -> str:
    """ã‚³ãƒ¡ãƒ³ãƒˆç”¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ–‡å­—åˆ—ã‚’ç”Ÿæˆï¼ˆRAGå¯¾å¿œï¼‰

    Args:
        improved_content: æ”¹å–„ã•ã‚ŒãŸå†…å®¹
        template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
        similar_issues: é¡ä¼¼Issueæƒ…å ±ï¼ˆRAGæ¤œç´¢çµæœï¼‰

    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®ã‚³ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—
    """
    template_display_names = {
        "feature_request": "æ©Ÿèƒ½è¦ä»¶",
        "bug_report": "ãƒã‚°å ±å‘Š",
    }
    template_display = template_display_names.get(template_name, template_name)

    comment = f"""## ğŸ¤– AIã«ã‚ˆã‚‹Issueè¨˜å…¥ä¾‹

**é¸å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: {template_display}

---

{improved_content}

---
"""

    # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
    if similar_issues and len(similar_issues) > 0:
        comment += "\n### ğŸ“š å‚è€ƒã«ã—ãŸé¡ä¼¼Issue\n\nã“ã®ä¾‹æ–‡ã¯ä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼š\n\n"
        for i, issue in enumerate(similar_issues, 1):
            comment += f"""{i}. **#{issue["issue_number"]}: {issue["issue_title"]}** ({issue["state"]})
   - é¡ä¼¼åº¦: {issue["similarity"]:.0%}
   - {issue["url"]}

"""
        comment += "---\n\n"

    comment += """ğŸ’¡ **ä½¿ã„æ–¹**: ä¸Šè¨˜ã®ä¾‹æ–‡ã‚’å‚è€ƒã«ã€Issueæœ¬æ–‡ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚"""
    if similar_issues and len(similar_issues) > 0:
        comment += "é¡ä¼¼Issueã‚‚ç¢ºèªã™ã‚‹ã¨ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
    else:
        comment += "å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åˆã‚ã›ã¦å†…å®¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"

    comment += "\n\n<!-- AI-generated comment -->\n"

    return comment


def index_all_issues(start: int = 1, end: int | None = None):
    """å…¨Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²ï¼ˆ--index-issues ãƒ¢ãƒ¼ãƒ‰ï¼‰

    Args:
        start: é–‹å§‹Issueç•ªå·
        end: çµ‚äº†Issueç•ªå·ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
    """
    # RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
    github_token = os.environ.get("GITHUB_TOKEN", "")
    if not github_token:
        print("Error: GITHUB_TOKEN not set")
        sys.exit(1)

    print("=== RAG Indexing Mode ===")
    print("Fetching issues from GitHub...")

    # Issueä¸€è¦§å–å¾—
    issues = fetch_all_issues(github_token, start, end)
    if not issues:
        print("No issues found")
        sys.exit(0)

    print(f"Found {len(issues)} issues to index")

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    voyage_client = VoyageEmbeddingClient(api_key=os.environ["VOYAGE_API_KEY"])
    qdrant_client = QdrantSearchClient(
        url=os.environ["QDRANT_URL"], api_key=os.environ["QDRANT_API_KEY"]
    )
    qdrant_client.ensure_collection(vector_size=256)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šå™¨
    detector = TemplateDetector()

    # å„Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²
    success_count = 0
    for i, issue in enumerate(issues, 1):
        print(f"[{i}/{len(issues)}] Indexing issue #{issue['number']}...")

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = create_issue_chunks(issue["title"], issue["body"])

        # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®š
        template_type = detector.detect(issue["body"], issue["title"])

        # Qdrantã«ç™»éŒ²
        qdrant_client.upsert_issue_chunks(
            issue_number=issue["number"],
            chunks=chunks,
            vectors=vectors,
            title=issue["title"],
            template_type=template_type,
            state=issue["state"],
            url=issue["url"],
            labels=issue.get("labels", []),
        )
        success_count += 1

    print("\n=== Indexing Complete ===")
    print(f"Success: {success_count}/{len(issues)} issues")


def update_single_issue(issue_number: int):
    """å˜ä¸€Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ï¼ˆ--update-single-issue ãƒ¢ãƒ¼ãƒ‰ï¼‰

    Args:
        issue_number: Issueç•ªå·
    """
    # RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
    github_token = os.environ.get("GITHUB_TOKEN", "")
    if not github_token:
        print("Error: GITHUB_TOKEN not set")
        sys.exit(1)

    print(f"=== Update Single Issue #{issue_number} ===")

    # Issueæƒ…å ±å–å¾—
    issue = fetch_issue_from_github(issue_number, github_token)
    if not issue:
        print(f"Error: Failed to fetch issue #{issue_number}")
        sys.exit(1)

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    voyage_client = VoyageEmbeddingClient(api_key=os.environ["VOYAGE_API_KEY"])
    qdrant_client = QdrantSearchClient(
        url=os.environ["QDRANT_URL"], api_key=os.environ["QDRANT_API_KEY"]
    )
    qdrant_client.ensure_collection(vector_size=256)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®š
    detector = TemplateDetector()
    template_type = detector.detect(issue["body"], issue["title"])

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = create_issue_chunks(issue["title"], issue["body"])

    # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
    vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

    # Qdrantã«ç™»éŒ²
    qdrant_client.upsert_issue_chunks(
        issue_number=issue["number"],
        chunks=chunks,
        vectors=vectors,
        title=issue["title"],
        template_type=template_type,
        state=issue["state"],
        url=issue["url"],
        labels=issue.get("labels", []),
    )

    print(f"Issue #{issue_number} updated successfully")


def main():
    # å¼•æ•°è§£æ
    parser = argparse.ArgumentParser(description="Issueè‡ªå‹•æ”¹å–„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (Phase 2)")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰",
    )
    parser.add_argument(
        "--index-issues",
        action="store_true",
        help="RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨Issueã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰",
    )
    parser.add_argument(
        "--update-single-issue",
        type=int,
        help="å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰ï¼ˆæŒ‡å®šã—ãŸIssueç•ªå·ã‚’æ›´æ–°ï¼‰",
    )
    parser.add_argument(
        "--start", type=int, default=1, help="RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é–‹å§‹Issueç•ªå·"
    )
    parser.add_argument("--end", type=int, help="RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ‚äº†Issueç•ªå·")
    args = parser.parse_args()

    # RAGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
    if args.index_issues:
        index_all_issues(start=args.start, end=args.end)
        sys.exit(0)

    # å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰
    if args.update_single_issue:
        update_single_issue(args.update_single_issue)
        sys.exit(0)

    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: Issueæ”¹å–„
    # ç’°å¢ƒå¤‰æ•°å–å¾—
    issue_body = os.environ.get("ISSUE_BODY", "")
    issue_title = os.environ.get("ISSUE_TITLE", "")
    issue_number = os.environ.get("ISSUE_NUMBER", "")
    api_key = os.environ.get("LLM_API_KEY", "")

    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not issue_number:
        print("Error: ISSUE_NUMBER not set")
        sys.exit(1)

    if not api_key:
        print("Error: LLM_API_KEY not set")
        sys.exit(1)

    # æ”¹å–„ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
    if not check_needs_improvement(issue_body, issue_title):
        print(f"Issue #{issue_number} does not need improvement (too short)")
        sys.exit(0)

    print(f"Processing issue #{issue_number}")
    print(f"Title: {issue_title}")
    print(f"Body length: {len(issue_body)} characters")

    # RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
    similar_issues = None

    if (
        os.getenv("QDRANT_URL")
        and os.getenv("QDRANT_API_KEY")
        and os.getenv("VOYAGE_API_KEY")
    ):
        print("RAG mode: Enabled")
        # RAGæ¤œç´¢
        voyage_client = VoyageEmbeddingClient(api_key=os.environ["VOYAGE_API_KEY"])
        qdrant_client = QdrantSearchClient(
            url=os.environ["QDRANT_URL"], api_key=os.environ["QDRANT_API_KEY"]
        )
        qdrant_client.ensure_collection(vector_size=256)

        # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        query_text = f"{issue_title}\n{issue_body}"
        query_vector = voyage_client.generate_embedding(query_text, dimensions=256)

        # é¡ä¼¼Issueæ¤œç´¢
        similar_issues = qdrant_client.search_similar_issues(query_vector, limit=3)

        if similar_issues:
            print(f"Found {len(similar_issues)} similar issues")
            for i, sim in enumerate(similar_issues, 1):
                print(
                    f"  {i}. #{sim['issue_number']}: {sim['issue_title'][:50]}... "
                    f"(similarity: {sim['similarity']:.1%})"
                )
        else:
            print("No similar issues found")
    else:
        print("RAG mode: Disabled")

    # æ”¹å–„å†…å®¹ã‚’ç”Ÿæˆ
    improved_content, template_name = generate_improved_content(
        issue_body, issue_title, api_key, similar_issues
    )

    # ã‚³ãƒ¡ãƒ³ãƒˆç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    output = format_comment(improved_content, template_name, similar_issues)

    # --dry-run ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã®ã¿
    if args.dry_run:
        print("\n" + "=" * 60)
        print("[DRY RUN] ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        print("=" * 60)
        print(output)
        print("=" * 60)
        sys.exit(0)

    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: GitHub CLIã§ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
    github_token = os.environ.get("GITHUB_TOKEN", "")
    if not github_token:
        print("Error: GITHUB_TOKEN not found")
        sys.exit(1)

    post_comment_via_gh(issue_number, output)

    # RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²ï¼ˆä¾‹æ–‡ç”Ÿæˆå¾Œï¼‰
    print("Indexing current issue to RAG...")
    detector = TemplateDetector()
    template_type = detector.detect(issue_body, issue_title)

    voyage_client = VoyageEmbeddingClient(api_key=os.environ["VOYAGE_API_KEY"])
    qdrant_client = QdrantSearchClient(
        url=os.environ["QDRANT_URL"], api_key=os.environ["QDRANT_API_KEY"]
    )
    qdrant_client.ensure_collection(vector_size=256)

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    chunks = create_issue_chunks(issue_title, issue_body)

    # å„ãƒãƒ£ãƒ³ã‚¯ã®Embeddingãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
    vectors = create_embeddings_for_chunks(chunks, voyage_client, dimensions=256)

    # Issueã®URLç”Ÿæˆ
    repo = os.environ.get("GITHUB_REPOSITORY", "")
    issue_url = f"https://github.com/{repo}/issues/{issue_number}" if repo else ""

    qdrant_client.upsert_issue_chunks(
        issue_number=int(issue_number),
        chunks=chunks,
        vectors=vectors,
        title=issue_title,
        template_type=template_type,
        state="open",
        url=issue_url,
        labels=[],
    )
    print("Issue indexed successfully")


if __name__ == "__main__":
    main()
